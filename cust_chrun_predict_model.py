# -*- coding: utf-8 -*-
"""cust_chrun_predict_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XeSqTfovj2QEw9apxsl6CnjdgEqA0nnd
"""

import pandas as pd
import numpy as np

df=pd.read_csv('Churn_Modelling.csv')

df.head()

df.tail()

df.shape

df.info()

df.isnull().sum()

df.describe(include='all')

df.columns

new_df=df.drop(['RowNumber','CustomerId','Surname'],axis=1)

new_df.head()

new_df['Geography'].unique()

new_df=pd.get_dummies(new_df,drop_first=True)

new_df.head()

new_df['Exited'].value_counts()

import seaborn as sns

sns.countplot(x='Exited',data=new_df)

X=new_df.drop('Exited',axis=1)
Y=new_df['Exited']

"""oversample and undersample"""

from imblearn.over_sampling import SMOTE

X_res,y_res=SMOTE().fit_resample(X,Y)

y_res.value_counts()

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X_res,y_res,test_size=0.20,random_state=42)

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

log=LogisticRegression()

log.fit(X_train,y_train)

y_pred1=log.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred1)

from sklearn.metrics import precision_score,recall_score,f1_score

precision_score(y_test,y_pred1)

recall_score(y_test,y_pred1)

f1_score(y_test,y_pred1)

"""precision=positive out of all positive(true positive and false positive)

recall=postive out of actual positive (true positive and false negative)

SVC
"""

from sklearn import svm

svm=svm.SVC()

svm.fit(X_train,y_train)

y_pred2=svm.predict(X_test)

accuracy_score(y_test,y_pred2)

precision_score(y_test,y_pred2)

f1_score(y_test,y_pred2)

"""k-Neighbour classifier"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()

knn.fit(X_train,y_train)

y_pred3=knn.predict(X_test)

accuracy_score(y_test,y_pred3)

precision_score(y_test,y_pred3)

f1_score(y_test,y_pred3)
#

"""Decision tree"""

from sklearn.tree import DecisionTreeClassifier
dt=DecisionTreeClassifier()

dt.fit(X_train,y_train)

y_pred4=dt.predict(X_test)

accuracy_score(y_test,y_pred4)

precision_score(y_test,y_pred4)

"""Random forest classifier"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier()

rf.fit(X_train,y_train)

y_pred5=rf.predict(X_test)

accuracy_score(y_test,y_pred5)

precision_score(y_test,y_pred5)

"""gradient boosting clasifier"""

from sklearn.ensemble import GradientBoostingClassifier
gb=GradientBoostingClassifier()

gb.fit(X_train,y_train)

y_pred6=gb.predict(X_test)

accuracy_score(y_test,y_pred6)

precision_score(y_test,y_pred6)

final_data1=pd.DataFrame({'Model':['LR','SVC','KNN','DT','RF','GB'],
                         'ACC':[accuracy_score(y_test,y_pred1),
                                accuracy_score(y_test,y_pred2),
                                accuracy_score(y_test,y_pred3),
                                accuracy_score(y_test,y_pred4),
                                accuracy_score(y_test,y_pred5),
                                accuracy_score(y_test,y_pred6)]})

import seaborn as sns

sns.barplot(x='Model', y='ACC', data=final_data1)

final_data=pd.DataFrame({'Model':['LR','SVC','KNN','DT','RF','GB'],
                         'PC':[precision_score(y_test,y_pred1),
                                precision_score(y_test,y_pred2),
                                precision_score(y_test,y_pred3),
                                precision_score(y_test,y_pred4),
                                precision_score(y_test,y_pred5),
                                precision_score(y_test,y_pred6)]})

sns.barplot(x='Model',y='PC',data=final_data)

final_data

sns.barplot(x=final_data['Model'],y=final_data['PC'])